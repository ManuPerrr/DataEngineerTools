{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet\n",
    "\n",
    "### Description du projet\n",
    "    - Création d'une application Web vous basant sur le package Flask.\n",
    "    - Récupération des données sur le web scrapées grâce à ce que vous aurez appris durant ce cours.\n",
    "    - Affichage des données de façon optimale, moteur de recherche, graphiques, etc. \n",
    "    - Utilisation d'une ou plusieurs bases de données abordées dans ce cours. \n",
    "    - Création d'une documentation technique et fonctionnelle.  \n",
    "    \n",
    "### Description \n",
    "    -Site utilisé : https://www.allocine.fr/\n",
    "    -robot.txt : https://www.allocine.fr/robots.txt\n",
    "    \n",
    "    -Récupération d'informations possibles : \n",
    "        (Scrap#1) Page : Top film (10x30 films par pages) : \n",
    "            Date/Durée/Genre/Note presse/Note spectateur/Nombre de votes/Synopsis/Budget/Langue/Nombre Récompense/Distributeur/Casting Principal/Réalisateur/Top critique Spectateur\n",
    "            (Scrap#2) Page Casting pour avoir la liste complète\n",
    "            (Scrap#3) Page des récompenses pour avoir le détail\n",
    "        (Scrap#1) Page : Films à l'affiche : Même données\n",
    "            (Scrap#4) Page Du box office pour relier à l'affiche \n",
    "        (Scrap#1) Page : Tous les films trié par popularité/Note presse/Note pop (15 films par page)\n",
    "    -Possible utilisation des données offrant une plus value avec ou sans graphe\n",
    "        -Histogramme des moyennes de note(pop ou presse)/Nombre de critique des films d'un réalisateur par année de sortie\n",
    "        -Diagramme circulaire des genres de film à l'affiche\n",
    "        -Graphe de l'évolution de box office d'un film à l'affiche sur la dernière semaine (à vérifier)\n",
    "        -Liste de film par paire de membre de casting \n",
    "        -Autres à définir\n",
    "\n",
    "    -Scraping : Utilisation de Scrapy préféré\n",
    "\n",
    "### Objectif :\n",
    "    -Choisir ce que l'on veut récupérer comme données\n",
    "    -Prendre en compte le robot.txt\n",
    "    -Récupération des données\n",
    "    -En faire une base de donnée \n",
    "    -Nettoyer la base de donnée\n",
    "    -Mettre en relation les bases de données (si plusieurs)\n",
    "    -Manipuler les données\n",
    "    -Faire la page web \n",
    "    -Faire la page web de manière interactive\n",
    "    \n",
    "\n",
    "### Questions :\n",
    "    -Est-ce que l'on peut utiliser Dash pour la page Flask ? \n",
    "    -Comment interpréter le robot.txt\n",
    "    -La documentation c'est un User guide + Developpeur Guide ou c'est un rapport des étapes/difficultés etc...\n",
    "    -Plus value nécessaire ?\n",
    "    \n",
    "### Réponse :\n",
    "\n",
    "Par rapport à la valeur ajouté il faudrait ajouter quelque chose qui existe ailleur\n",
    "Faudrait rassembler les données de allociné et les lier aux données d’autres sites internets \n",
    "Exemple : \n",
    "Si on récupère le casting d’allociné on peut ajouter un scrap twitter pour associer au nombre de follower, on peut alors voir les films avec le plus de follower d’acteur et essayer de faire des liaisons théoriques\n",
    "Ca peut être autre chose et pas que des réseaux sociaux \n",
    "=> faut ajouter une dimension/introduire une notion qui n’existe pas ailleur\n",
    "=> Un peu du bonus mais très cool à faire ne plus\n",
    "\n",
    "Comment relier le nom des acteurs aux twitter ?\n",
    "\t=> Moteur de recherche, on récupère le pseudo, on va sur la page twitter puis les foll\n",
    "\t=> Rechercher un site qui recense les page twitter des personnalités \n",
    "\t=> \n",
    "\n",
    "Est-ce que l’on peut utiliser dash ? \n",
    "=> Attendre les conseilles de Raphaël \n",
    "\n",
    "\n",
    "Comment interpréter le robot.txt \n",
    "=> Rien n’est interdit, c’est juste que le site n’aimerait pas trop mais voilà on fait pas de bénéfices derrières donc on peut y aller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification de l'installation de scrapy et importation\n",
    "!pip install scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 14:48:33 [scrapy.utils.log] INFO: Scrapy 2.4.0 started (bot: scrapybot)\n",
      "2020-12-14 14:48:33 [scrapy.utils.log] INFO: Versions: lxml 4.6.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Nov 18 2020, 13:49:49) - [GCC 8.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.2.1, Platform Linux-4.19.128-microsoft-standard-x86_64-with-glibc2.2.5\n",
      "2020-12-14 14:48:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2020-12-14 14:48:33 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2020-12-14 14:48:33 [scrapy.extensions.telnet] INFO: Telnet Password: 3acf3b3904374b02\n",
      "2020-12-14 14:48:33 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2020-12-14 14:48:33 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-12-14 14:48:33 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-12-14 14:48:33 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-12-14 14:48:33 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-12-14 14:48:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-12-14 14:48:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-12-14 14:48:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.allocine.fr/film/meilleurs/> (referer: None)\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'Forrest Gump'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'La Ligne verte'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'La Liste de Schindler'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'Le Parrain'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': '12 hommes en colère'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'Les Evadés'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'Le Seigneur des anneaux : le retour du roi'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'Your Name'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': 'The Dark Knight, Le Chevalier Noir'}\n",
      "2020-12-14 14:48:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.allocine.fr/film/meilleurs/>\n",
      "{'Titre': \"Vol au-dessus d'un nid de coucou\"}\n",
      "2020-12-14 14:48:33 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-12-14 14:48:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 230,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 59993,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.437053,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 12, 14, 14, 48, 33, 950123),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 11,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 56406016,\n",
      " 'memusage/startup': 56406016,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2020, 12, 14, 14, 48, 33, 513070)}\n",
      "2020-12-14 14:48:33 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider film_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
